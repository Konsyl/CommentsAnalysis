{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
    "    text = re.sub('@[^\\s]+', 'USER', text)\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = ['id', 'date', 'name', 'text', 'typr', 'rep', 'rtw', 'faw', 'stcount', 'foll', 'frien', 'listcount']\n",
    "data_positive = pd.read_csv('D:\\Programming\\Data\\\\positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
    "data_negative = pd.read_csv('D:\\Programming\\Data\\\\negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
    "\n",
    "#сбалансированный датасет\n",
    "sample_size = min(data_positive.shape[0], data_negative.shape[0])\n",
    "raw_data = np.concatenate((data_positive['text'].values[:sample_size],\n",
    "                           data_negative['text'].values[:sample_size]), axis=0)\n",
    "labels = [1] * sample_size + [0] * sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\Programming\\Data\\\\2Wec.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in data_positive['text']:\n",
    "        rasp = i.split(' ')\n",
    "        text=''\n",
    "        for j in rasp:\n",
    "            if j.find('@')==-1 and j!='RT' and j.find('http')==-1:\n",
    "                text=text+' '+j\n",
    "        print(text,file=f)\n",
    "    for i in data_negative['text']:\n",
    "        rasp = i.split(' ')\n",
    "        text=''\n",
    "        for j in rasp:\n",
    "            if j.find('@')==-1:\n",
    "                text=text+' '+j\n",
    "        print(text,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [preprocess_text(t) for t in raw_data]\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "data = gensim.models.word2vec.LineSentence('D:\\Programming\\Data\\\\2Wec.txt') \n",
    "model = Word2Vec(data, size=200, window=5, min_count=3, workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 21:20:05,204 : INFO : collecting all words and their counts\n",
      "2020-08-26 21:20:05,206 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-08-26 21:20:05,349 : INFO : PROGRESS: at sentence #10000, processed 94710 words, keeping 34916 word types\n",
      "2020-08-26 21:20:05,426 : INFO : PROGRESS: at sentence #20000, processed 187941 words, keeping 61349 word types\n",
      "2020-08-26 21:20:05,495 : INFO : PROGRESS: at sentence #30000, processed 283680 words, keeping 85158 word types\n",
      "2020-08-26 21:20:05,593 : INFO : PROGRESS: at sentence #40000, processed 376614 words, keeping 106186 word types\n",
      "2020-08-26 21:20:05,710 : INFO : PROGRESS: at sentence #50000, processed 474515 words, keeping 126652 word types\n",
      "2020-08-26 21:20:05,779 : INFO : PROGRESS: at sentence #60000, processed 568676 words, keeping 146120 word types\n",
      "2020-08-26 21:20:05,847 : INFO : PROGRESS: at sentence #70000, processed 659277 words, keeping 163927 word types\n",
      "2020-08-26 21:20:05,927 : INFO : PROGRESS: at sentence #80000, processed 754780 words, keeping 182369 word types\n",
      "2020-08-26 21:20:06,025 : INFO : PROGRESS: at sentence #90000, processed 846842 words, keeping 199339 word types\n",
      "2020-08-26 21:20:06,131 : INFO : PROGRESS: at sentence #100000, processed 941148 words, keeping 216037 word types\n",
      "2020-08-26 21:20:06,203 : INFO : PROGRESS: at sentence #110000, processed 1031093 words, keeping 231645 word types\n",
      "2020-08-26 21:20:06,291 : INFO : PROGRESS: at sentence #120000, processed 1128017 words, keeping 247640 word types\n",
      "2020-08-26 21:20:06,364 : INFO : PROGRESS: at sentence #130000, processed 1221189 words, keeping 263155 word types\n",
      "2020-08-26 21:20:06,432 : INFO : PROGRESS: at sentence #140000, processed 1310076 words, keeping 277710 word types\n",
      "2020-08-26 21:20:06,571 : INFO : PROGRESS: at sentence #150000, processed 1410053 words, keeping 294698 word types\n",
      "2020-08-26 21:20:06,657 : INFO : PROGRESS: at sentence #160000, processed 1507075 words, keeping 309784 word types\n",
      "2020-08-26 21:20:06,732 : INFO : PROGRESS: at sentence #170000, processed 1606317 words, keeping 324379 word types\n",
      "2020-08-26 21:20:06,804 : INFO : PROGRESS: at sentence #180000, processed 1704409 words, keeping 338417 word types\n",
      "2020-08-26 21:20:06,890 : INFO : PROGRESS: at sentence #190000, processed 1803898 words, keeping 352536 word types\n",
      "2020-08-26 21:20:06,965 : INFO : PROGRESS: at sentence #200000, processed 1899772 words, keeping 366491 word types\n",
      "2020-08-26 21:20:07,056 : INFO : PROGRESS: at sentence #210000, processed 1999795 words, keeping 379945 word types\n",
      "2020-08-26 21:20:07,170 : INFO : PROGRESS: at sentence #220000, processed 2093873 words, keeping 392812 word types\n",
      "2020-08-26 21:20:07,252 : INFO : PROGRESS: at sentence #230000, processed 2189361 words, keeping 405526 word types\n",
      "2020-08-26 21:20:07,321 : INFO : PROGRESS: at sentence #240000, processed 2281486 words, keeping 418389 word types\n",
      "2020-08-26 21:20:07,424 : INFO : PROGRESS: at sentence #250000, processed 2374248 words, keeping 431056 word types\n",
      "2020-08-26 21:20:07,531 : INFO : PROGRESS: at sentence #260000, processed 2466364 words, keeping 443613 word types\n",
      "2020-08-26 21:20:07,603 : INFO : PROGRESS: at sentence #270000, processed 2562104 words, keeping 456373 word types\n",
      "2020-08-26 21:20:07,622 : INFO : collected 459688 word types from a corpus of 2586731 raw words and 272606 sentences\n",
      "2020-08-26 21:20:07,624 : INFO : Loading a fresh vocabulary\n",
      "2020-08-26 21:20:08,024 : INFO : effective_min_count=3 retains 70779 unique words (15% of original 459688, drops 388909)\n",
      "2020-08-26 21:20:08,024 : INFO : effective_min_count=3 leaves 2148584 word corpus (83% of original 2586731, drops 438147)\n",
      "2020-08-26 21:20:08,318 : INFO : deleting the raw counts dictionary of 459688 items\n",
      "2020-08-26 21:20:08,332 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2020-08-26 21:20:08,334 : INFO : downsampling leaves estimated 1791081 word corpus (83.4% of prior 2148584)\n",
      "2020-08-26 21:20:08,560 : INFO : estimated required memory for 70779 words and 200 dimensions: 148635900 bytes\n",
      "2020-08-26 21:20:08,561 : INFO : resetting layer weights\n",
      "2020-08-26 21:20:22,866 : INFO : training model with 4 workers on 70779 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-08-26 21:20:23,887 : INFO : EPOCH 1 - PROGRESS: at 26.85% examples, 471068 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:24,897 : INFO : EPOCH 1 - PROGRESS: at 54.99% examples, 482283 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:25,903 : INFO : EPOCH 1 - PROGRESS: at 80.50% examples, 478624 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:26,584 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-26 21:20:26,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-26 21:20:26,593 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-26 21:20:26,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-26 21:20:26,607 : INFO : EPOCH - 1 : training on 2586731 raw words (1791478 effective words) took 3.7s, 480275 effective words/s\n",
      "2020-08-26 21:20:27,625 : INFO : EPOCH 2 - PROGRESS: at 26.85% examples, 469186 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:28,639 : INFO : EPOCH 2 - PROGRESS: at 54.61% examples, 477023 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:29,640 : INFO : EPOCH 2 - PROGRESS: at 79.70% examples, 473510 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:30,372 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-26 21:20:30,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-26 21:20:30,384 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-26 21:20:30,393 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-26 21:20:30,395 : INFO : EPOCH - 2 : training on 2586731 raw words (1790829 effective words) took 3.8s, 473387 effective words/s\n",
      "2020-08-26 21:20:31,401 : INFO : EPOCH 3 - PROGRESS: at 26.09% examples, 462081 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:32,411 : INFO : EPOCH 3 - PROGRESS: at 52.43% examples, 460082 words/s, in_qsize 1, out_qsize 0\n",
      "2020-08-26 21:20:33,418 : INFO : EPOCH 3 - PROGRESS: at 76.64% examples, 457080 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:34,301 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-26 21:20:34,304 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-26 21:20:34,315 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-26 21:20:34,321 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-26 21:20:34,322 : INFO : EPOCH - 3 : training on 2586731 raw words (1791064 effective words) took 3.9s, 456758 effective words/s\n",
      "2020-08-26 21:20:35,334 : INFO : EPOCH 4 - PROGRESS: at 23.67% examples, 418489 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:36,346 : INFO : EPOCH 4 - PROGRESS: at 49.69% examples, 434035 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:37,352 : INFO : EPOCH 4 - PROGRESS: at 72.95% examples, 432742 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:38,358 : INFO : EPOCH 4 - PROGRESS: at 97.73% examples, 434592 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:38,422 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-26 21:20:38,424 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-26 21:20:38,433 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-26 21:20:38,442 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-26 21:20:38,443 : INFO : EPOCH - 4 : training on 2586731 raw words (1790802 effective words) took 4.1s, 435166 effective words/s\n",
      "2020-08-26 21:20:39,460 : INFO : EPOCH 5 - PROGRESS: at 24.88% examples, 436834 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:40,464 : INFO : EPOCH 5 - PROGRESS: at 50.53% examples, 441586 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:41,480 : INFO : EPOCH 5 - PROGRESS: at 74.07% examples, 438638 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:42,491 : INFO : EPOCH 5 - PROGRESS: at 98.90% examples, 438333 words/s, in_qsize 0, out_qsize 0\n",
      "2020-08-26 21:20:42,510 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-26 21:20:42,515 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-26 21:20:42,516 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-26 21:20:42,531 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-26 21:20:42,533 : INFO : EPOCH - 5 : training on 2586731 raw words (1791288 effective words) took 4.1s, 438610 effective words/s\n",
      "2020-08-26 21:20:42,534 : INFO : training on a 12933655 raw words (8955461 effective words) took 19.7s, 455341 effective words/s\n",
      "2020-08-26 21:20:42,536 : INFO : saving Word2Vec object under D:\\Programming\\Data\\model2Wec.w2v, separately None\n",
      "2020-08-26 21:20:42,537 : INFO : storing np array 'vectors' to D:\\Programming\\Data\\model2Wec.w2v.wv.vectors.npy\n",
      "2020-08-26 21:20:44,590 : INFO : not storing attribute vectors_norm\n",
      "2020-08-26 21:20:44,591 : INFO : storing np array 'syn1neg' to D:\\Programming\\Data\\model2Wec.w2v.trainables.syn1neg.npy\n",
      "2020-08-26 21:20:45,202 : INFO : not storing attribute cum_table\n",
      "2020-08-26 21:20:45,371 : INFO : saved D:\\Programming\\Data\\model2Wec.w2v\n"
     ]
    }
   ],
   "source": [
    "model.save(\"D:\\Programming\\Data\\\\model2Wec.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_LENGTH = 26\n",
    "# Размер словаря\n",
    "NUM = 100000\n",
    "\n",
    "def get_sequences(tokenizer, x):\n",
    "    sequences = tokenizer.texts_to_sequences(x)\n",
    "    return pad_sequences(sequences, maxlen=SENTENCE_LENGTH)\n",
    "\n",
    "# Токенизатор\n",
    "tokenizer = Tokenizer(num_words=NUM)\n",
    "#tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "#x_train_seq = get_sequences(tokenizer, x_train)\n",
    "#x_test_seq = get_sequences(tokenizer, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 21:57:07,110 : INFO : loading Word2Vec object from D:\\Programming\\Data\\model2Wec.w2v\n",
      "2020-08-26 21:57:07,323 : INFO : loading wv recursively from D:\\Programming\\Data\\model2Wec.w2v.wv.* with mmap=None\n",
      "2020-08-26 21:57:07,324 : INFO : loading vectors from D:\\Programming\\Data\\model2Wec.w2v.wv.vectors.npy with mmap=None\n",
      "2020-08-26 21:57:07,359 : INFO : setting ignored attribute vectors_norm to None\n",
      "2020-08-26 21:57:07,360 : INFO : loading vocabulary recursively from D:\\Programming\\Data\\model2Wec.w2v.vocabulary.* with mmap=None\n",
      "2020-08-26 21:57:07,362 : INFO : loading trainables recursively from D:\\Programming\\Data\\model2Wec.w2v.trainables.* with mmap=None\n",
      "2020-08-26 21:57:07,363 : INFO : loading syn1neg from D:\\Programming\\Data\\model2Wec.w2v.trainables.syn1neg.npy with mmap=None\n",
      "2020-08-26 21:57:07,398 : INFO : setting ignored attribute cum_table to None\n",
      "2020-08-26 21:57:07,399 : INFO : loaded D:\\Programming\\Data\\model2Wec.w2v\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec.load('D:\\Programming\\Data\\\\model2Wec.w2v')\n",
    "DIM = w2v_model.vector_size \n",
    "# Инициализируем матрицу embedding слоя нулями\n",
    "embedding_matrix = np.zeros((NUM, DIM))\n",
    "# Добавляем NUM=100000 наиболее часто встречающихся слов из обучающей выборки в embedding слой\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= NUM:\n",
    "        break\n",
    "    if word in w2v_model.wv.vocab.keys():\n",
    "        embedding_matrix[i] = w2v_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_input = Input(shape=(SENTENCE_LENGTH,), dtype='int32')\n",
    "tweet_encoder = Embedding(NUM, DIM, input_length=SENTENCE_LENGTH,\n",
    "                          weights=[embedding_matrix], trainable=False)(tweet_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Dense, concatenate, Activation, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "\n",
    "branches = []\n",
    "x = Dropout(0.2)(tweet_encoder)\n",
    "\n",
    "for size, filters_count in [(2, 10), (3, 10), (4, 10), (5, 10)]:\n",
    "    for i in range(filters_count):\n",
    "        branch = Conv1D(filters=1, kernel_size=size, padding='valid', activation='relu')(x)\n",
    "        branch = GlobalMaxPooling1D()(branch)\n",
    "        branches.append(branch)\n",
    "# Конкатенируем карты признаков\n",
    "x = concatenate(branches, axis=1)\n",
    "# Добавляем dropout-регуляризацию\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(30, activation='relu')(x)\n",
    "x = Dense(1)(x)\n",
    "output = Activation('sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[tweet_input], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 26)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 26, 200)      20000000    input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 26, 200)      0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_120 (Conv1D)             (None, 25, 1)        401         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_121 (Conv1D)             (None, 25, 1)        401         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, 25, 1)        401         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)             (None, 25, 1)        401         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_124 (Conv1D)             (None, 25, 1)        401         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_125 (Conv1D)             (None, 25, 1)        401         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_126 (Conv1D)             (None, 25, 1)        401         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_127 (Conv1D)             (None, 25, 1)        401         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_128 (Conv1D)             (None, 25, 1)        401         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_129 (Conv1D)             (None, 25, 1)        401         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_130 (Conv1D)             (None, 24, 1)        601         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)             (None, 24, 1)        601         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)             (None, 24, 1)        601         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)             (None, 24, 1)        601         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)             (None, 24, 1)        601         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)             (None, 24, 1)        601         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_136 (Conv1D)             (None, 24, 1)        601         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_137 (Conv1D)             (None, 24, 1)        601         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_138 (Conv1D)             (None, 24, 1)        601         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_139 (Conv1D)             (None, 24, 1)        601         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)             (None, 23, 1)        801         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)             (None, 23, 1)        801         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_142 (Conv1D)             (None, 23, 1)        801         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_143 (Conv1D)             (None, 23, 1)        801         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_144 (Conv1D)             (None, 23, 1)        801         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_145 (Conv1D)             (None, 23, 1)        801         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_146 (Conv1D)             (None, 23, 1)        801         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_147 (Conv1D)             (None, 23, 1)        801         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_148 (Conv1D)             (None, 23, 1)        801         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_149 (Conv1D)             (None, 23, 1)        801         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_150 (Conv1D)             (None, 22, 1)        1001        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_151 (Conv1D)             (None, 22, 1)        1001        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_152 (Conv1D)             (None, 22, 1)        1001        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_153 (Conv1D)             (None, 22, 1)        1001        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_154 (Conv1D)             (None, 22, 1)        1001        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_155 (Conv1D)             (None, 22, 1)        1001        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_156 (Conv1D)             (None, 22, 1)        1001        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_157 (Conv1D)             (None, 22, 1)        1001        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_158 (Conv1D)             (None, 22, 1)        1001        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_159 (Conv1D)             (None, 22, 1)        1001        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_120 (Globa (None, 1)            0           conv1d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_121 (Globa (None, 1)            0           conv1d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_122 (Globa (None, 1)            0           conv1d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_123 (Globa (None, 1)            0           conv1d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_124 (Globa (None, 1)            0           conv1d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_125 (Globa (None, 1)            0           conv1d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_126 (Globa (None, 1)            0           conv1d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_127 (Globa (None, 1)            0           conv1d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_128 (Globa (None, 1)            0           conv1d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_129 (Globa (None, 1)            0           conv1d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_130 (Globa (None, 1)            0           conv1d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_131 (Globa (None, 1)            0           conv1d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_132 (Globa (None, 1)            0           conv1d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_133 (Globa (None, 1)            0           conv1d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_134 (Globa (None, 1)            0           conv1d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_135 (Globa (None, 1)            0           conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_136 (Globa (None, 1)            0           conv1d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_137 (Globa (None, 1)            0           conv1d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_138 (Globa (None, 1)            0           conv1d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_139 (Globa (None, 1)            0           conv1d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_140 (Globa (None, 1)            0           conv1d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_141 (Globa (None, 1)            0           conv1d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_142 (Globa (None, 1)            0           conv1d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_143 (Globa (None, 1)            0           conv1d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_144 (Globa (None, 1)            0           conv1d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_145 (Globa (None, 1)            0           conv1d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_146 (Globa (None, 1)            0           conv1d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_147 (Globa (None, 1)            0           conv1d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_148 (Globa (None, 1)            0           conv1d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_149 (Globa (None, 1)            0           conv1d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_150 (Globa (None, 1)            0           conv1d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_151 (Globa (None, 1)            0           conv1d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_152 (Globa (None, 1)            0           conv1d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_153 (Globa (None, 1)            0           conv1d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_154 (Globa (None, 1)            0           conv1d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_155 (Globa (None, 1)            0           conv1d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_156 (Globa (None, 1)            0           conv1d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_157 (Globa (None, 1)            0           conv1d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_158 (Globa (None, 1)            0           conv1d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_159 (Globa (None, 1)            0           conv1d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 40)           0           global_max_pooling1d_120[0][0]   \n",
      "                                                                 global_max_pooling1d_121[0][0]   \n",
      "                                                                 global_max_pooling1d_122[0][0]   \n",
      "                                                                 global_max_pooling1d_123[0][0]   \n",
      "                                                                 global_max_pooling1d_124[0][0]   \n",
      "                                                                 global_max_pooling1d_125[0][0]   \n",
      "                                                                 global_max_pooling1d_126[0][0]   \n",
      "                                                                 global_max_pooling1d_127[0][0]   \n",
      "                                                                 global_max_pooling1d_128[0][0]   \n",
      "                                                                 global_max_pooling1d_129[0][0]   \n",
      "                                                                 global_max_pooling1d_130[0][0]   \n",
      "                                                                 global_max_pooling1d_131[0][0]   \n",
      "                                                                 global_max_pooling1d_132[0][0]   \n",
      "                                                                 global_max_pooling1d_133[0][0]   \n",
      "                                                                 global_max_pooling1d_134[0][0]   \n",
      "                                                                 global_max_pooling1d_135[0][0]   \n",
      "                                                                 global_max_pooling1d_136[0][0]   \n",
      "                                                                 global_max_pooling1d_137[0][0]   \n",
      "                                                                 global_max_pooling1d_138[0][0]   \n",
      "                                                                 global_max_pooling1d_139[0][0]   \n",
      "                                                                 global_max_pooling1d_140[0][0]   \n",
      "                                                                 global_max_pooling1d_141[0][0]   \n",
      "                                                                 global_max_pooling1d_142[0][0]   \n",
      "                                                                 global_max_pooling1d_143[0][0]   \n",
      "                                                                 global_max_pooling1d_144[0][0]   \n",
      "                                                                 global_max_pooling1d_145[0][0]   \n",
      "                                                                 global_max_pooling1d_146[0][0]   \n",
      "                                                                 global_max_pooling1d_147[0][0]   \n",
      "                                                                 global_max_pooling1d_148[0][0]   \n",
      "                                                                 global_max_pooling1d_149[0][0]   \n",
      "                                                                 global_max_pooling1d_150[0][0]   \n",
      "                                                                 global_max_pooling1d_151[0][0]   \n",
      "                                                                 global_max_pooling1d_152[0][0]   \n",
      "                                                                 global_max_pooling1d_153[0][0]   \n",
      "                                                                 global_max_pooling1d_154[0][0]   \n",
      "                                                                 global_max_pooling1d_155[0][0]   \n",
      "                                                                 global_max_pooling1d_156[0][0]   \n",
      "                                                                 global_max_pooling1d_157[0][0]   \n",
      "                                                                 global_max_pooling1d_158[0][0]   \n",
      "                                                                 global_max_pooling1d_159[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 40)           0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           1230        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            31          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1)            0           dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,029,301\n",
      "Trainable params: 29,301\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[precision, recall, f1])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 21:58:59,930 : WARNING : `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4198/4198 [==============================] - 332s 79ms/step - loss: 0.6486 - precision: 0.6164 - recall: 0.6371 - f1: 0.6159 - val_loss: 0.6228 - val_precision: 0.6237 - val_recall: 0.7560 - val_f1: 0.6770\n",
      "Epoch 2/10\n",
      "4198/4198 [==============================] - 336s 80ms/step - loss: 0.6251 - precision: 0.6395 - recall: 0.6772 - f1: 0.6494 - val_loss: 0.6088 - val_precision: 0.6601 - val_recall: 0.6641 - val_f1: 0.6547\n",
      "Epoch 3/10\n",
      "4198/4198 [==============================] - 323s 77ms/step - loss: 0.6161 - precision: 0.6500 - recall: 0.6829 - f1: 0.6576 - val_loss: 0.6078 - val_precision: 0.6854 - val_recall: 0.6022 - val_f1: 0.6332\n",
      "Epoch 4/10\n",
      "4198/4198 [==============================] - 331s 79ms/step - loss: 0.6102 - precision: 0.6540 - recall: 0.6914 - f1: 0.6643 - val_loss: 0.6007 - val_precision: 0.6836 - val_recall: 0.6422 - val_f1: 0.6548\n",
      "Epoch 5/10\n",
      "4198/4198 [==============================] - 329s 78ms/step - loss: 0.6058 - precision: 0.6559 - recall: 0.7002 - f1: 0.6695 - val_loss: 0.5969 - val_precision: 0.6638 - val_recall: 0.7191 - val_f1: 0.6838\n",
      "Epoch 6/10\n",
      "4198/4198 [==============================] - 332s 79ms/step - loss: 0.6027 - precision: 0.6606 - recall: 0.7022 - f1: 0.6731 - val_loss: 0.5989 - val_precision: 0.6653 - val_recall: 0.7140 - val_f1: 0.6820\n",
      "Epoch 7/10\n",
      "4198/4198 [==============================] - 352s 84ms/step - loss: 0.6001 - precision: 0.6646 - recall: 0.7013 - f1: 0.6747 - val_loss: 0.5952 - val_precision: 0.6914 - val_recall: 0.6388 - val_f1: 0.6566\n",
      "Epoch 8/10\n",
      "4198/4198 [==============================] - 335s 80ms/step - loss: 0.5980 - precision: 0.6650 - recall: 0.7045 - f1: 0.6766 - val_loss: 0.5932 - val_precision: 0.6514 - val_recall: 0.7677 - val_f1: 0.6984\n",
      "Epoch 9/10\n",
      "4198/4198 [==============================] - 331s 79ms/step - loss: 0.5958 - precision: 0.6663 - recall: 0.7065 - f1: 0.6787 - val_loss: 0.5910 - val_precision: 0.6900 - val_recall: 0.6704 - val_f1: 0.6729\n",
      "Epoch 10/10\n",
      "4198/4198 [==============================] - 329s 78ms/step - loss: 0.5940 - precision: 0.6699 - recall: 0.7059 - f1: 0.6798 - val_loss: 0.5910 - val_precision: 0.6887 - val_recall: 0.6711 - val_f1: 0.6722\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"D:\\Programming\\Data\\\\modelsdir\\\\cnn-frozen-embeddings-{epoch:02d}-{val_f1:.2f}.hdf5\",\n",
    "                             monitor='val_f1', save_best_only=True, mode='max', period=1)\n",
    "history = model.fit(x_train_seq, np.array(y_train), batch_size=32, epochs=10, validation_split=0.25, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 22:56:28,194 : WARNING : From C:\\Users\\61515\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-08-26 22:56:28,239 : WARNING : From C:\\Users\\61515\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "2020-08-26 22:56:37,948 : INFO : Assets written to: D:\\Programming\\Data\\cnn\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('D:\\Programming\\Data\\\\cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.models.load_model('D:\\Programming\\Data\\\\cnn',\n",
    "                                custom_objects={'f1':f1, 'precision':precision, 'recall':recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33419538]]\n"
     ]
    }
   ],
   "source": [
    "comment=get_sequences(tokenizer, ['А прошлым вечером ногу отпилил ради этой шутки'])\n",
    "print(model.predict(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('D:\\Programming\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='https://pikabu.ru/story/kak_vospitat_besshumnogo_nindzyu_7674675'\n",
    "driver.get(path)\n",
    "while True:\n",
    "    try:\n",
    "        button = driver.find_element_by_class_name('button_width_100 comments__more-button')\n",
    "        button.click()\n",
    "        time.sleep(10)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "elem = driver.find_elements_by_xpath(\"//div[@class='page-story__comments']//*[@class='comment__content']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([comment.text for comment in elem])\n",
    "\n",
    "comment=get_sequences(tokenizer, [comment.text for comment in elem])\n",
    "predictions=model.predict(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001E8E65C50F0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comments_data=pd.DataFrame(data=(np.array(predictions)))\n",
    "comments_data.hist(bins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot=comments_data[comments_data[0]<0.25]\n",
    "mid=comments_data[(comments_data[0]>0.25) & (comments_data[0]<0.75)]\n",
    "top=comments_data[comments_data[0]>0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq(x):\n",
    "    if x>0.75: return 'top'\n",
    "    if x<=0.75 and x>=0.25: return 'mid'\n",
    "    if x<0.25: return 'bot'\n",
    "\n",
    "comments_data['rang']=pd.Series([eq(x) for x in comments_data[0]], dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e8e63ccb70>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments_data.rang.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "driver.get(path)\n",
    "while True:\n",
    "    try:\n",
    "        button = driver.find_element_by_class_name('button_width_100 comments__more-button')\n",
    "        button.click()\n",
    "        time.sleep(10)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "elem = driver.find_elements_by_xpath(\n",
    "    \"//div[@class='page-story__comments']//*[@class='comment__header']//*[@class='comment__datetime hint']\")\n",
    "dates=[datetime.datetime.strptime((date.get_attribute('datetime'))[0:10], \"%Y-%m-%d\") for date in elem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_count=pd.Series(pd.Series(dates).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e8e679dc18>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments_count.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
